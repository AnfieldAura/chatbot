{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77db5d59-9fa2-4835-ae0f-5bd85a32547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting flask-cors\n",
      "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\addan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\addan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.1.4)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\addan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (8.1.8)\n",
      "Collecting blinker>=1.9 (from flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\addan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\addan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: itsdangerous, blinker, flask, flask-cors\n",
      "Successfully installed blinker-1.9.0 flask-3.1.0 flask-cors-5.0.1 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flask flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50fe8f6d-92b7-4e9c-8590-261359c0bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Preprocessed data saved as 'cleaned_data.json'\n",
      "‚úÖ FAISS index saved as 'index.faiss'\n",
      "üöÄ Chatbot API running at http://localhost:5000/chat\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.103:5000\n",
      "Press CTRL+C to quit\n",
      "192.168.0.103 - - [05/Apr/2025 23:23:48] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Apr/2025 23:24:45] \"OPTIONS /chat HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2025 23:24:45] \"POST /chat HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2025 23:24:58] \"OPTIONS /chat HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Apr/2025 23:24:59] \"POST /chat HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# File paths\n",
    "DATA_FILE = \"cleaned_data.json\"\n",
    "FAISS_INDEX_FILE = \"index.faiss\"\n",
    "\n",
    "# Load the model & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "def get_embedding(text):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).numpy()\n",
    "input_file = \"scrape11.txt\"\n",
    "\n",
    "if not os.path.exists(input_file):\n",
    "    print(f\"‚ùå Error: '{input_file}' not found.\")\n",
    "else:\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    def chunk_text(text_list, chunk_size=200):\n",
    "        chunks = []\n",
    "        chunk = \"\"\n",
    "        for line in text_list:\n",
    "            line = clean_text(line)\n",
    "            if len(chunk) + len(line) <= chunk_size:\n",
    "                chunk += \" \" + line\n",
    "            else:\n",
    "                chunks.append(chunk.strip())\n",
    "                chunk = line\n",
    "        if chunk:\n",
    "            chunks.append(chunk.strip())\n",
    "        return chunks\n",
    "\n",
    "    cleaned_data = list(set([line.strip() for line in data if line.strip() != \"\"]))\n",
    "    final_chunks = chunk_text(cleaned_data)\n",
    "\n",
    "    json_data = [{\"id\": i, \"text\": chunk} for i, chunk in enumerate(final_chunks)]\n",
    "    with open(DATA_FILE, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Preprocessed data saved as '{DATA_FILE}'\")\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "text_chunks = [entry[\"text\"] for entry in json_data]\n",
    "embeddings = np.array([get_embedding(text)[0] for text in text_chunks], dtype=\"float32\")\n",
    "\n",
    "embedding_size = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "\n",
    "print(f\"‚úÖ FAISS index saved as '{FAISS_INDEX_FILE}'\")\n",
    "# Load FAISS index and JSON\n",
    "index = faiss.read_index(FAISS_INDEX_FILE)\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "    documents = json.load(file)\n",
    "text_chunks = [entry[\"text\"] for entry in documents]\n",
    "\n",
    "def extract_short_answer(full_text, query):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', full_text)\n",
    "    query_words = set(query.lower().split())\n",
    "    best_sentence = \"\"\n",
    "    max_overlap = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_words = set(sentence.lower().split())\n",
    "        overlap = len(query_words & sentence_words)\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sentence = sentence\n",
    "    return best_sentence if best_sentence else full_text\n",
    "\n",
    "def search_faiss(query, top_k=3):\n",
    "    query = clean_text(query)\n",
    "    query_embedding = get_embedding(query).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    retrieved_docs = [text_chunks[i] for i in indices[0]]\n",
    "    if not retrieved_docs:\n",
    "        return \"Sorry, I couldn't find a relevant response.\"\n",
    "    return extract_short_answer(retrieved_docs[0], query)\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import threading\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    user_input = request.json.get('message', '')\n",
    "    if not user_input:\n",
    "        return jsonify({'response': \"Please enter a message.\"})\n",
    "    result = search_faiss(user_input)\n",
    "    return jsonify({'response': result})\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\n",
    "threading.Thread(target=run_flask).start()\n",
    "print(\"üöÄ Chatbot API running at http://localhost:5000/chat\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
